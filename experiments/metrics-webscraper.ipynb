{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee47bc82-f297-4c8e-b5e1-d48e5959c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2d4ce3-d1e7-459e-b86c-999b47acfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82f6eb26-82df-434b-91a6-720e714d47be",
   "metadata": {},
   "source": [
    "# save all python notebooks on kaggle\n",
    "with open(\"output-2.txt\", \"w\") as file:\n",
    "    for i in range(21):  # Change range as needed\n",
    "        i += 1\n",
    "        result = subprocess.run(\n",
    "            f\"kaggle kernels list --page-size 50 -v --kernel-type notebook --language python --page {i}\",\n",
    "            shell=True,\n",
    "            stdout=file,\n",
    "            stderr=subprocess.STDOUT\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ff325fb-5359-4146-a54c-0a77aa6637cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST RUN\n",
    "def extract_metrics_kaggle(url):\n",
    "    #url = 'https://www.kaggle.com/code/m1nty03/rice-type-classification'\n",
    "    name = url.split(\"www.kaggle.com/code/\")\n",
    "    name = name[-1].replace(\"/\", \"--\")\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, 'rendered-kernel-content'))\n",
    "    )\n",
    "    \n",
    "    iframe = driver.find_element(By.ID, 'rendered-kernel-content')\n",
    "    iframe_src = iframe.get_attribute('src')\n",
    "    response = requests.get(iframe_src)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    return regex_metrics(soup)\n",
    "\n",
    "\n",
    "def regex_metrics(soup):\n",
    "    pattern1 = r'Epoch\\s*(\\d+)/\\d+.*? - accuracy:\\s*(\\d+\\.\\d+)\\s*- loss:\\s*(\\d+\\.\\d+)'\n",
    "    pattern2 = r'Epoch\\s*(\\d+)/\\d+.*? - accuracy:\\s*(\\d+\\.\\d+)\\s*- loss:\\s*(\\d+\\.\\d+)(?:.*? - val_accuracy:\\s*(\\d+\\.\\d+)\\s*- val_loss:\\s*(\\d+\\.\\d+))?'\n",
    "    matches = re.findall(pattern2, soup.text, re.DOTALL)\n",
    "    \n",
    "    structured_data = []\n",
    "    for match in matches:\n",
    "        epoch = int(match[0])\n",
    "        acc = float(match[1])\n",
    "        loss = float(match[2])\n",
    "        val_acc = float(match[3]) if match[3] else None\n",
    "        val_loss = float(match[4]) if match[4] else None\n",
    "        structured_data.append((epoch, acc, loss, val_acc, val_loss))\n",
    "    \n",
    "    # Create a DataFrame for better readability\n",
    "    df = pd.DataFrame(structured_data, columns=['Epoch', 'Accuracy', 'Loss', 'Val_Accuracy', 'Val_Loss'])\n",
    "    if len(df) > 0:\n",
    "        print(f\"found {len(df)} metrics for {name}\")\n",
    "        df.to_csv(name + \".csv\", index=False)\n",
    "        return df\n",
    "    else:\n",
    "        return\n",
    "\n",
    "#df = extract_metrics(\"https://www.kaggle.com/code/adhamtarek147/cifar-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ec5678-7b56-4063-8a9d-e18444cfa6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                            | 33/950 [02:44<1:33:17,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████                                                                            | 59/950 [04:16<54:41,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 9 metrics for wanizyanaqila--face-mask-detection-mobilenetv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                           | 63/950 [04:32<56:35,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 19 metrics for shahdalaa11111111--mnist-comparasion-between-models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                           | 64/950 [04:35<54:38,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 100 metrics for gramchelle--building-an-artificial-neural-network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▌                                                                           | 65/950 [04:38<52:49,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 14 metrics for hamza062--cats-vs-dogs-cnn-vgg16-with-98-accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▉                                                                        | 84/950 [06:04<1:30:24,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▏                                                                      | 109/950 [07:44<57:24,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 12 metrics for charfeddineiheb--compt-rendu-lab-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▎                                                                      | 111/950 [07:52<56:09,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 8 metrics for tusharkharat--rsnalss200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▏                                                                   | 124/950 [08:47<1:01:00,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for wanizyanaqila--medical-mask-dataset-inceptionv3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▌                                                                     | 126/950 [08:55<55:56,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 50 metrics for satyakiranv--nextwordpred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▋                                                                   | 130/950 [09:14<1:02:16,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for pranavdekate--96-accuracy-using-cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████                                                                   | 135/950 [09:42<1:26:26,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▌                                                                  | 141/950 [10:29<2:04:11,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for tanmaybakare--loan-default-prediction-99-9-accurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                   | 147/950 [10:52<57:44,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 metrics for agustinbottos--filmaffinity-netflix-review-rate-prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▌                                                               | 177/950 [13:04<1:39:17,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for akash10rout--covid-pnuemonia-convnext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▌                                                                | 185/950 [13:33<48:55,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 40 metrics for vivekmotwani1410--bbc-news-lstm-ann-rnn-cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▎                                                              | 186/950 [13:43<1:14:47,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▉                                                                | 189/950 [13:55<57:26,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 13 metrics for nguynngcminhzz--dogs-vs-cats-classification-minh-and-tri\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████                                                                | 191/950 [14:02<48:26,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for nehagupta09--loan-prediction-using-ann\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▊                                                              | 212/950 [15:18<49:19,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for akash10rout--3-convnext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▌                                                             | 220/950 [15:47<45:25,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for akash10rout--2-convnext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▏                                                           | 221/950 [15:57<1:10:54,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/aidenmiele/lab5-aiden-valerie-sophie Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▏                                                           | 222/950 [16:02<1:05:12,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for bharratkhanna--cv-classification-warehouse-automation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████▊                                                             | 224/950 [16:08<50:58,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 20 metrics for shriramvibhute--dog-vs-cat-classifier-using-lenet-and-resnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▌                                                            | 233/950 [16:38<42:28,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for akash10rout--convnext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                          | 237/950 [16:59<1:08:17,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▋                                                      | 288/950 [20:15<1:01:57,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▉                                                       | 296/950 [20:41<37:19,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for mrayasatriatama--rock-papers-scissors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████                                                     | 306/950 [21:27<1:13:07,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 340 metrics for thanradabooranarombk--sp2naja\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▏                                                    | 307/950 [21:31<1:02:18,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 50 metrics for arnavsmayan--cnn-xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▎                                                     | 313/950 [21:51<41:34,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 50 metrics for ahmedashrafhelmi--ecg-classification-rnn-gru-lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▍                                                    | 326/950 [22:36<32:42,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for manarmohamed24--cnn-fashion-mnist-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▌                                                   | 339/950 [23:30<57:58,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▏                                                  | 346/950 [23:58<42:00,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 3 metrics for wanizyanaqila--face-mask-detection-densenet201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▍                                                  | 349/950 [24:10<38:51,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 129 metrics for mdmahmudunnobi--iris-recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████▉                                                  | 355/950 [24:30<34:34,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 41 metrics for tolstoyjustin--brain-tumor-mri-classification-using-tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▏                                                 | 358/950 [24:46<49:28,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 metrics for angelarentsi--lstm-cici-2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████▉                                                 | 368/950 [25:20<34:46,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 metrics for banu777--handwritten-digits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████▊                                               | 390/950 [26:42<52:03,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████▊                                             | 414/950 [28:15<39:25,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for thomasamgedfathi--brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████▍                                           | 433/950 [29:26<35:02,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 18 metrics for youssefelbadry10--cnn-image-classification-tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▏                                          | 441/950 [30:01<47:50,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████▉                                         | 462/950 [31:21<29:56,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 33 metrics for guanlintao--keras-model-design-brain-tumor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████▏                                        | 465/950 [31:33<31:39,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 100 metrics for elmuatazelhariri--ann-fetal-health-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▍                                      | 492/950 [33:35<46:34,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▌                                      | 494/950 [33:42<35:01,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 50 metrics for mhmdelshoraky--breast-cancer-wisconsin-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▋                                      | 495/950 [33:44<30:58,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for mohammedezzeldean--simple-text-classification-rnn-lstm-gru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████▎                                     | 502/950 [34:08<24:51,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 20 metrics for goduguanilhimam--soon-to-be-god-of-handwritten-digits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▌                                   | 529/950 [36:08<28:17,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for nirmalgaud--emotion-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▋                                   | 531/950 [36:16<28:22,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 metrics for getanmolgupta01--text-summarization-lstm-encoder-decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████▋                                  | 543/950 [37:11<45:14,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████▏                                | 561/950 [38:41<33:04,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for raghavgoel01--3-efficientnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████▉                               | 581/950 [40:10<23:42,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 40 metrics for sahityasetu--computer-vision-binary-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████                               | 583/950 [40:17<22:41,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 24 metrics for mahmoudshaheen1134--movies-sentiment-analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▊                              | 591/950 [40:58<29:11,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 15 metrics for alihassanml--fight-dataset-prediction-resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████                              | 594/950 [41:16<36:49,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▎                            | 609/950 [42:41<36:45,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 3 metrics for marlenatpanagiotakou--ieee-ntua-sb-ml-team-digit-recognizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████▌                           | 624/950 [43:47<19:12,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 19 metrics for muhammadhamzanawaz--brain-tumor-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████▋                           | 626/950 [43:54<19:27,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 metrics for wanizyanaqila--face-mask-detection-tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████▉                           | 628/950 [44:05<24:53,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for amnydv17--forgery-detection-2024-dl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████▎                          | 633/950 [44:23<21:14,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for dhruv5018--dog-breed-classsification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████▎                         | 645/950 [45:19<30:35,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████▋                         | 650/950 [45:38<20:54,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 295 metrics for duygujones--flowers-cnn-10-transfer-learning-part-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████▌                      | 684/950 [48:35<17:08,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 20 metrics for sakhadib--character-sign-language-detection-densenet201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▌                     | 696/950 [49:47<34:49,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▉                 | 747/950 [53:16<20:06,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▎              | 776/950 [55:12<11:38,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 30 metrics for medouazane--tomato-leaf-disease-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▉              | 783/950 [55:40<11:36,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 15 metrics for swarnabh31--computervision-lungcancerprediction-acc-99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████▏            | 798/950 [57:14<15:55,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████▊            | 806/950 [57:44<08:55,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 67 metrics for sarthakaggarwal267--lung-cancer-detection-inception-v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████▍           | 812/950 [58:05<07:54,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 195 metrics for minanabil11111212--kersa-mlp-on-mnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████▌         | 838/950 [59:55<07:13,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 70 metrics for ahmedashrafhelmi--brain-tumor-classification-using-cnn-nasnetmobile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████▍        | 846/950 [1:00:24<06:29,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 20 metrics for sulaniishara--handwritten-digit-recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████▋        | 849/950 [1:00:41<09:34,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████▋     | 886/950 [1:03:18<04:29,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 8 metrics for omargowaily--98-accuracy-in-spam-detection-model-by-lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████▊     | 887/950 [1:03:24<04:44,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 340 metrics for gygyygygy--digit-recognizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████▊    | 899/950 [1:04:22<03:27,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 41 metrics for ahmedhassan23mahmoud--image-classification-using-cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████▉    | 900/950 [1:04:33<05:03,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kaggle.com/code/ref Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF7C771B095+29557]\n",
      "\t(No symbol) [0x00007FF7C768FA50]\n",
      "\t(No symbol) [0x00007FF7C754B56A]\n",
      "\t(No symbol) [0x00007FF7C759F695]\n",
      "\t(No symbol) [0x00007FF7C759F8EC]\n",
      "\t(No symbol) [0x00007FF7C75EB777]\n",
      "\t(No symbol) [0x00007FF7C75C71CF]\n",
      "\t(No symbol) [0x00007FF7C75E851C]\n",
      "\t(No symbol) [0x00007FF7C75C6F33]\n",
      "\t(No symbol) [0x00007FF7C759116F]\n",
      "\t(No symbol) [0x00007FF7C75922D1]\n",
      "\tGetHandleVerifier [0x00007FF7C7A4C96D+3378253]\n",
      "\tGetHandleVerifier [0x00007FF7C7A98497+3688311]\n",
      "\tGetHandleVerifier [0x00007FF7C7A8D1CB+3642539]\n",
      "\tGetHandleVerifier [0x00007FF7C77DA6B6+813462]\n",
      "\t(No symbol) [0x00007FF7C769AB5F]\n",
      "\t(No symbol) [0x00007FF7C7696B74]\n",
      "\t(No symbol) [0x00007FF7C7696D10]\n",
      "\t(No symbol) [0x00007FF7C7685C1F]\n",
      "\tBaseThreadInitThunk [0x00007FFF67757374+20]\n",
      "\tRtlUserThreadStart [0x00007FFF680DCC91+33]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████▉   | 913/950 [1:05:20<02:08,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for youssefabdelghfar--twitter-sentiment-analysis-nlp-lstm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████▏| 940/950 [1:07:01<00:36,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10 metrics for renjiabarai--hair-type-detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 950/950 [1:07:40<00:00,  4.27s/it]\n"
     ]
    }
   ],
   "source": [
    "refs = pd.read_csv(\"output.txt\")\n",
    "for ref in tqdm(list(refs[\"ref\"])[120:]):\n",
    "    url = \"https://www.kaggle.com/code/\" + ref\n",
    "    #print(f\"processing url {url}\")\n",
    "    try:\n",
    "        extract_metrics_kaggle(url)\n",
    "    except Exception as e:\n",
    "        print(url, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cfa948-47ed-44a4-9cdf-99d472a61386",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801f862-34d4-4941-8745-20dbfc200a3b",
   "metadata": {},
   "source": [
    "## GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f94d64b-b1d1-4cf3-8475-f9939206c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Replace with your GitHub personal access token\n",
    "GITHUB_TOKEN = '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'\n",
    "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
    "\n",
    "# GitHub Search API query for notebooks containing \"Epoch 1/\"\n",
    "search_query = 'Epoch 1/'\n",
    "search_url = f'https://api.github.com/search/code?q={search_query}'\n",
    "response = requests.get(search_url, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44cc6ff7-0c53-4b29-8ca3-d21fedbb463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch search results from GitHub API\n",
    "if response.status_code == 200:\n",
    "    results = response.json()\n",
    "    for item in results['items'][:1]:\n",
    "        # Construct the raw URL for the notebook\n",
    "        repo = item['repository']['full_name']\n",
    "        path = item['path']\n",
    "        raw_url = f'https://raw.githubusercontent.com/{repo}/master/{path}'\n",
    "\n",
    "        r = requests.get(raw_url)\n",
    "        soup = bs(r.text, 'html.parser')\n",
    "        regex_metrics(soup)\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71d02081-3ec4-4380-93e3-20401f962dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 十八、Keras\\n\\n> 作者：[Chris Albon](https://chrisalbon.com/)\\n> \\n> 译者：[飞龙](https://github.com/wizardforcel)\\n> \\n> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)\\n\\n## 添加丢弃\\n\\n![](img/797049479fae3d337256efa33157af1a.jpg)\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们想要的特征数量\\nnumber_of_features = 1000\\n\\n# 从电影评论数据加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 将电影评论数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n```\\n\\n在 Keras 中，我们可以通过在我们的网络架构中添加`Dropout`层来实现丢弃。 每个`Dropout`层将丢弃每批中的一定数量的上一层单元，它是由用户定义的超参数。 请记住，在 Keras 中，输入层被假定为第一层，而不是使用`add`添加。 因此，如果我们想要将丢弃添加到输入层，我们在其中添加的图层是一个丢弃层。 该层包含输入层单元的比例，即`0.2`和`input_shape`，用于定义观测数据的形状。 接下来，在每个隐藏层之后添加一个带有`0.5`的丢弃层。\\n\\n```py\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 为输入层添加丢弃层\\nnetwork.add(layers.Dropout(0.2, input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 为先前的隐藏层添加丢弃层\\nnetwork.add(layers.Dropout(0.5))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 为先前的隐藏层添加丢弃层\\nnetwork.add(layers.Dropout(0.5))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标向量\\n                      epochs=3, # 迭代数量\\n                      verbose=0, # 无输出\\n                      batch_size=100, # 每个批量的观测数量\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n## 卷积神经网络\\n\\n```py\\nimport numpy as np\\nfrom keras.datasets import mnist\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Flatten\\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\\nfrom keras.utils import np_utils\\nfrom keras import backend as K \\n\\n# 设置颜色通道值优先\\nK.set_image_data_format('channels_first')\\n\\n# 设置种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置图像信息\\nchannels = 1\\nheight = 28\\nwidth = 28\\n\\n# 从 MNIST 数据集加载数据和目标\\n(train_data, train_target), (test_data, test_target) = mnist.load_data()\\n\\n# 将训练图像数据的形状变为特征\\ntrain_data = train_data.reshape(train_data.shape[0], channels, height, width)\\n\\n# 将测试图像数据的形状变为特征\\ntest_data = test_data.reshape(test_data.shape[0], channels, height, width)\\n\\n# 将像素缩放到 0 和 1 之间\\ntrain_features = train_data / 255\\ntest_features = test_data / 255\\n\\n# 将目标单热编码\\ntrain_target = np_utils.to_categorical(train_target)\\ntest_target = np_utils.to_categorical(test_target)\\nnumber_of_classes = test_target.shape[1]\\n```\\n\\n卷积神经网络（也称为 ConvNets）是一种流行的网络类型，已被证明在计算机视觉上非常有效（例如识别猫狗，飞机甚至热狗）。前馈神经网络完全可以在图像上使用，其中每个像素都是一个特征。 但是，这样做时我们遇到了两个主要问题。\\n\\n首先，前馈神经网络不考虑像素的空间结构。 例如，在 10x10 的像素图像中，我们可以将其转换为 100 个像素特征的矢量，并且在这种情况下，前馈将认为第一特征（例如像素值）与第十个和第十一个特征具有相同的关系。 然而，实际上，第 10 个特征表示第一个特征的远侧的像素，而第 11 个特征表示紧邻第一个特征的像素。\\n\\n其次，与之相关，前馈神经网络学习特征中的全局关系而不是局部规律。 在更实际的术语中，这意味着前馈神经网络无法检测到对象，无论它出现在图像中哪个位置。 例如，假设我们正在训练神经网络识别面部，这些面部可能出现在图像的任何位置，从右上角到中间到左下角。 卷积神经网络的威力就是它们处理这两个问题（和其他问题）的能力。\\n\\n```py\\n# 创建神经网络\\nnetwork = Sequential()\\n\\n# 添加卷积层，带有 64 个过滤器\\n# 5x5 窗口和 ReLU 激活函数\\nnetwork.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(channels, width, height), activation='relu'))\\n\\n# 添加带有 2x2 窗口的最大池化层\\nnetwork.add(MaxPooling2D(pool_size=(2, 2)))\\n\\n# 添加丢弃层\\nnetwork.add(Dropout(0.5))\\n\\n# 添加展开输入的层\\nnetwork.add(Flatten())\\n\\n# 添加带有 ReLU 激活函数的 128 个单元的全连接层\\nnetwork.add(Dense(128, activation='relu'))\\n\\n# 添加丢弃层\\nnetwork.add(Dropout(0.5))\\n\\n# 添加带有 softmax 激活函数的全连接层\\nnetwork.add(Dense(number_of_classes, activation='softmax'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='categorical_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n\\n# 训练神经网络\\nnetwork.fit(train_features, # 特征\\n            train_target, # 目标\\n            epochs=2, # 迭代数量\\n            verbose=0, # 不要在每个迭代之后打印描述\\n            batch_size=1000, # 每个批量的观测数\\n            validation_data=(test_features, test_target)) # 用于评估的数据\\n\\n#  \\n```\\n\\n## 用于二分类的前馈神经网络\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 1000\\n\\n# 从电影评论数据集加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 将电影评论数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n```\\n\\n因为这是二元分类问题，所以一种常见的选择是在单个单元的输出层中使用 sigmoid 激活函数。\\n\\n```py\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n```\\n\\n在Keras，我们使用`fit`方法训练我们的神经网络。 需要定义六个重要参数。 前两个参数是训练数据的特征和目标向量。\\n\\n`epochs`参数定义训练数据时要使用的迭代数。 `verbose`确定在训练过程中输出多少信息，`0`没有输出，`1`输出进度条，`2`在每个迭代输出一行日志。 `batch_size`设置在更新参数之前通过网络传播的观测数。\\n\\n最后，我们提供了一组用于评估模型的测试数据。 这些测试特征和目标向量可以是`validation_data`的参数，它们将使用它们进行评估。 或者，我们可以使用`validation_split`来定义，我们想要进行评估训练数据的哪一部分。\\n\\n在 scikit-learn 中`fit`方法返回一个训练好的模型，但是在 Keras 中，`fit`方法返回一个`History`对象，包含每个迭代的损失值和表现指标。\\n\\n```py\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标向量\\n                      epochs=3, # 迭代数量\\n                      verbose=1, # 每个迭代之后打印描述\\n                      batch_size=100, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n\\n'''\\nTrain on 25000 samples, validate on 25000 samples\\nEpoch 1/3\\n25000/25000 [==============================] - 2s - loss: 0.4215 - acc: 0.8102 - val_loss: 0.3385 - val_acc: 0.8558\\nEpoch 2/3\\n25000/25000 [==============================] - 1s - loss: 0.3241 - acc: 0.8646 - val_loss: 0.3261 - val_acc: 0.8626\\nEpoch 3/3\\n25000/25000 [==============================] - 2s - loss: 0.3120 - acc: 0.8700 - val_loss: 0.3268 - val_acc: 0.8593 \\n'''\\n```\\n\\n## 用于多分类的前馈神经网络\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import reuters\\nfrom keras.utils.np_utils import to_categorical\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 5000\\n\\n# 加载特征和目标数据\\n(train_data, train_target_vector), (test_data, test_target_vector) = reuters.load_data(num_words=number_of_features)\\n\\n# 将特征数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n\\n# 单热编码目标向量来创建目标矩阵\\ntrain_target = to_categorical(train_target_vector)\\ntest_target = to_categorical(test_target_vector)\\n```\\n\\n在这个例子中，我们使用适合于多类分类的损失函数，分类交叉熵损失函数，`categorical_crossentropy`。\\n\\n```py\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=100, activation='relu', input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=100, activation='relu'))\\n\\n# 添加带有 Softmax 激活函数的全连接层\\nnetwork.add(layers.Dense(units=46, activation='softmax'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='categorical_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标向量\\n                      epochs=3, # 三个迭代\\n                      verbose=0, # 没有输出\\n                      batch_size=100, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n## 用于回归的前馈神经网络\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\nfrom sklearn.datasets import make_regression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn import preprocessing\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 生成特征矩阵和目标向量\\nfeatures, target = make_regression(n_samples = 10000,\\n                                   n_features = 3,\\n                                   n_informative = 3,\\n                                   n_targets = 1,\\n                                   noise = 0.0,\\n                                   random_state = 0)\\n\\n# 将我们的数据划分为训练和测试集\\ntrain_features, test_features, train_target, test_target = train_test_split(features, \\n                                                                            target, \\n                                                                            test_size=0.33, \\n                                                                            random_state=0)\\n\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=32, activation='relu', input_shape=(train_features.shape[1],)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=32, activation='relu'))\\n\\n# 添加没有激活函数的全连接层\\nnetwork.add(layers.Dense(units=1))\\n```\\n\\n因为我们正在训练回归，所以我们应该使用适当的损失函数和评估度量，在我们的例子中是均方误差：\\n\\n![](img/tex-1a68df3b73be15a6da50bd6cfdba832a.gif)\\n\\n其中 ![](img/tex-7b8b965ad4bca0e41ab51de7b31363a1.gif) 是观测数量，![](img/tex-18daef71b5d25ce76b8628a81e4fc76b.gif) 是我们试图预测的目标 ![](img/tex-415290769594460e2e485922904f345d.gif) 对于观测 ![](img/tex-865c0c0b4ab0e063e5caa3387c1a8741.gif) 的真实值， ![](img/tex-1aa7c4b9ac179483858f457df9ee441b.gif) 是 ![](img/tex-18daef71b5d25ce76b8628a81e4fc76b.gif) 的模型预测值。\\n\\n```py\\n# 编译神经网络\\nnetwork.compile(loss='mse', # MSE\\n                optimizer='RMSprop', # 优化算法\\n                metrics=['mse']) # MSE\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标向量\\n                      epochs=10, # 迭代数量\\n                      verbose=0, # 无输出\\n                      batch_size=100, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n## LSTM 循环神经网络\\n\\n通常我们拥有我们想要分类的文本数据。 虽然可以使用一种卷积网络，但我们将专注于一种更流行的选择：循环神经网络。循环神经网络的关键特征，是信息在网络中循环。 这为循环神经网络提供了一种存储器，可用于更好地理解序列数据。流行的循环神经网络类型是长期短期记忆（LSTM）网络，它允许信息在网络中向后循环。\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing import sequence\\nfrom keras import models\\nfrom keras import layers\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 1000\\n\\n# 从电影评论数据集加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 使用填充或者截断，使每个观测具有 400 个特征\\ntrain_features = sequence.pad_sequences(train_data, maxlen=400)\\ntest_features = sequence.pad_sequences(test_data, maxlen=400)\\n\\n# 查看第一个观测\\nprint(train_data[0])\\n\\n'''\\n[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32] \\n'''\\n\\n# 查看第一个观测\\ntest_features[0]\\n\\n'''\\narray([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\\n         0,   0,   0,   1,  89,  27,   2,   2,  17, 199, 132,   5,   2,\\n        16,   2,  24,   8, 760,   4,   2,   7,   4,  22,   2,   2,  16,\\n         2,  17,   2,   7,   2,   2,   9,   4,   2,   8,  14, 991,  13,\\n       877,  38,  19,  27, 239,  13, 100, 235,  61, 483,   2,   4,   7,\\n         4,  20, 131,   2,  72,   8,  14, 251,  27,   2,   7, 308,  16,\\n       735,   2,  17,  29, 144,  28,  77,   2,  18,  12], dtype=int32) \\n'''\\n\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加嵌入层\\nnetwork.add(layers.Embedding(input_dim=number_of_features, output_dim=128))\\n\\n# 添加带有 128 个单元的 LSTM 层\\nnetwork.add(layers.LSTM(units=128))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='Adam', # Adam 优化\\n                metrics=['accuracy']) # 准确率表现度量\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标\\n                      epochs=3, # 迭代数量\\n                      verbose=0, # 不在每个迭代之后打印描述\\n                      batch_size=1000, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n## 神经网络的提前停止\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 1000\\n\\n# 从电影评论数据集加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 将电影评论数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n```\\n\\n在 Keras 中，我们可以将提权停止实现为回调函数。 回调是可以在训练过程的某些阶段应用的函数，例如在每个迭代结束时。 具体来说，在我们的解决方案中，我们包含了`EarlyStopping(monitor='val_loss', patience=2)`，来定义我们想要监控每个迭代的测试（验证）损失，并且在两个迭代之后如果测试损失没有改善，训练就中断。 但是，由于我们设置了`patience=2`，我们不会得到最好的模型，而是最佳模型两个时代后的模型。 因此，可选地，我们可以包含第二个操作，`ModelCheckpoint`，它在每个检查点之后将模型保存到文件中（如果由于某种原因中断了多天的训练会话，这可能很有用。如果我们设置`save_best_only = True`，`ModelCheckpoint`将只保存最佳模型，这对我们有帮助。\\n\\n```py\\n# 将回调函数设置为提前停止训练，并保存到目前为止最好的模型\\ncallbacks = [EarlyStopping(monitor='val_loss', patience=2),\\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标向量\\n                      epochs=20, # 迭代数量\\n                      callbacks=callbacks, # 提前停止\\n                      verbose=0, # 每个迭代之后打印描述\\n                      batch_size=100, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n## 神经网络的参数正则化\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\nfrom keras import regularizers\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 1000\\n\\n# 从电影评论数据集加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 将电影评论数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n```\\n\\n在 Keras 中，我们可以通过添加带有`kernel_regularizer = regularizers.l2(0.01)`的层，来增加权重正则化。 在这个例子中，`0.01`确定我们如何惩罚更高的参数值。\\n\\n```py\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数和 L2 正则化的全连接层\\nnetwork.add(layers.Dense(units=16, \\n                         activation='relu', \\n                         kernel_regularizer=regularizers.l2(0.01),\\n                         input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数和 L2 正则化的全连接层\\nnetwork.add(layers.Dense(units=16, \\n                         kernel_regularizer=regularizers.l2(0.01),\\n                         activation='relu'))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标向量\\n                      epochs=3, # 迭代数量\\n                      verbose=0, # 无输出\\n                      batch_size=100, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n## 为神经网络预处理数据\\n\\n通常，神经网络的参数被初始化（即，创建）为小的随机数。 当特征值远大于参数值时，神经网络通常表现不佳。 此外，由于观测的特征值在通过单个单元时将被组合，因此所有特征具有相同的比例是很重要的。\\n\\n由于这些原因，最佳实践（尽管并非总是必要的，例如当我们的特征都是二元时）是标准化每个特征，使得特征的值均值为 0 和标准差为 1。这可以使用 scikit-learn 的`StandardScaler`轻松完成。\\n\\n```py\\n# 加载库\\nfrom sklearn import preprocessing\\nimport numpy as np\\n\\n# 创建特征\\nfeatures = np.array([[-100.1, 3240.1], \\n                     [-200.2, -234.1], \\n                     [5000.5, 150.1], \\n                     [6000.6, -125.1], \\n                     [9000.9, -673.1]])\\n\\n# 创建缩放器\\nscaler = preprocessing.StandardScaler()\\n\\n# 转换特征\\nfeatures_standardized = scaler.fit_transform(features)\\n\\n# 展示特征\\nfeatures_standardized\\n\\n'''\\narray([[-1.12541308,  1.96429418],\\n       [-1.15329466, -0.50068741],\\n       [ 0.29529406, -0.22809346],\\n       [ 0.57385917, -0.42335076],\\n       [ 1.40955451, -0.81216255]]) \\n'''\\n\\n# 打印均值和标准差\\nprint('Mean:', round(features_standardized[:,0].mean()))\\nprint('Standard deviation:', features_standardized[:,0].std())\\n\\n'''\\nMean: 0.0\\nStandard deviation: 1.0 \\n'''\\n```\\n\\n# 保存模型的训练过程\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\nfrom keras.callbacks import ModelCheckpoint\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 1000\\n\\n# 从电影评论数据集加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 将电影评论数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n```\\n\\n在每个得带之后，`ModelCheckpoint`将模型保存到`filepath`参数指定的位置。 如果我们只包含一个文件名（例如`models.hdf5`），那么每个迭代都会用最新的模型覆盖该文件。 如果我们只想根据某些损失函数的表现保存最佳模型，我们可以设置`save_best_only = True`和`monitor ='val_loss'`，如果模型的测试损失比以前更差，则不覆盖文件 。 或者，我们可以将每个迭代的模型保存到自己的文件，方法是将迭代编号和测试损失得分包含在文件名本身中。 例如，如果我们将`filepath`设置为`model_{epoch:02d}_{val_loss:.2f}.hdf5`，那么模型的文件名称为 `model_10_0.35.hdf5`（注意迭代编号的索引从 0 开始），它包含第 11 个迭代之后的测试损失值 0.33。\\n\\n```py\\n# 将回调函数设置为提前停止训练\\n# 并保存目前为止最好的模型\\ncheckpoint = [ModelCheckpoint(filepath='models.hdf5')]\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # 目标向量\\n                      epochs=3, # 迭代数量\\n                      callbacks=checkpoint, # Checkpoint\\n                      verbose=0, # 无输出\\n                      batch_size=100, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n# 调优神经网络超参数\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras import models\\nfrom keras import layers\\nfrom keras.wrappers.scikit_learn import KerasClassifier\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.datasets import make_classification\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 特征数\\nnumber_of_features = 100\\n\\n# 生成特征矩阵和目标向量\\nfeatures, target = make_classification(n_samples = 10000,\\n                                       n_features = number_of_features,\\n                                       n_informative = 3,\\n                                       n_redundant = 0,\\n                                       n_classes = 2,\\n                                       weights = [.5, .5],\\n                                       random_state = 0)\\n\\n# 创建返回已编译网络的函数\\ndef create_network(optimizer='rmsprop'):\\n\\n    # 创建神经网络\\n    network = models.Sequential()\\n\\n    # 添加带有 ReLU 激活函数的全连接层\\n    network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\\n\\n    # 添加带有 ReLU 激活函数的全连接层\\n    network.add(layers.Dense(units=16, activation='relu'))\\n\\n    # 添加带有 Sigmoid 激活函数的全连接层\\n    network.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n    # 编译神经网络\\n    network.compile(loss='binary_crossentropy', # 交叉熵\\n                    optimizer=optimizer, # 优化器\\n                    metrics=['accuracy']) # 准确率表现度量\\n\\n    # 返回编译的网络\\n    return network\\n\\n# 包装 Keras 模型，使其能够用于 sklearn\\nneural_network = KerasClassifier(build_fn=create_network, verbose=0)\\n\\n# 创建超参数空间\\nepochs = [5, 10]\\nbatches = [5, 10, 100]\\noptimizers = ['rmsprop', 'adam']\\n\\n# 创建超参数选项\\nhyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\\n\\n# 创建网格搜索\\ngrid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters)\\n\\n# 拟合网格搜索\\ngrid_result = grid.fit(features, target)\\n\\n# 查看神经网络的最佳超参数\\ngrid_result.best_params_\\n\\n# {'batch_size': 5, 'epochs': 5, 'optimizer': 'rmsprop'} \\n```\\n\\n## 可视化损失历史\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\nimport matplotlib.pyplot as plt\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 10000\\n\\n# 从电影评论数据集加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 将电影评论数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # Target\\n                      epochs=15, # 迭代数量\\n                      verbose=0, # 无输出\\n                      batch_size=1000, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n\\n# 得到训练和测试损失历史\\ntraining_loss = history.history['loss']\\ntest_loss = history.history['val_loss']\\n\\n# 创建迭代数量\\nepoch_count = range(1, len(training_loss) + 1)\\n\\n# 可视化损失历史\\nplt.plot(epoch_count, training_loss, 'r--')\\nplt.plot(epoch_count, test_loss, 'b-')\\nplt.legend(['Training Loss', 'Test Loss'])\\nplt.xlabel('Epoch')\\nplt.ylabel('Loss')\\nplt.show();\\n```\\n\\n![png](https://chrisalbon.com/deep_learning/keras/visualize_loss_history/visualize_loss_history_12_0.png)\\n\\n## 可视化神经网络架构\\n\\n```py\\n# 加载库\\nfrom keras import models\\nfrom keras import layers\\nfrom IPython.display import SVG\\nfrom keras.utils.vis_utils import model_to_dot\\nfrom keras.utils import plot_model\\n\\n# 使用 TensorFlow 后端\\n\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu', input_shape=(10,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 可视化网络架构\\nSVG(model_to_dot(network, show_shapes=True).create(prog='dot', format='svg'))\\n```\\n\\n![svg](https://chrisalbon.com/deep_learning/keras/visualize_neural_network_architecture/visualize_neural_network_architecture_6_0.svg)\\n\\n```py\\n# 将绘图保存到文件\\nplot_model(network, show_shapes=True, to_file='network.png')\\n```\\n\\n## 可视化表现历史\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras.datasets import imdb\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras import models\\nfrom keras import layers\\nimport matplotlib.pyplot as plt\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 设置我们希望的特征数\\nnumber_of_features = 10000\\n\\n# 从电影评论数据集加载数据和目标向量\\n(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features)\\n\\n# 将电影评论数据转换为单热编码的特征矩阵\\ntokenizer = Tokenizer(num_words=number_of_features)\\ntrain_features = tokenizer.sequences_to_matrix(train_data, mode='binary')\\ntest_features = tokenizer.sequences_to_matrix(test_data, mode='binary')\\n\\n# 创建神经网络\\nnetwork = models.Sequential()\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\\n\\n# 添加带有 ReLU 激活函数的全连接层\\nnetwork.add(layers.Dense(units=16, activation='relu'))\\n\\n# 添加带有 Sigmoid 激活函数的全连接层\\nnetwork.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n# 编译神经网络\\nnetwork.compile(loss='binary_crossentropy', # 交叉熵\\n                optimizer='rmsprop', # RMSProp\\n                metrics=['accuracy']) # 准确率表现度量\\n\\n# 训练神经网络\\nhistory = network.fit(train_features, # 特征\\n                      train_target, # Target\\n                      epochs=15, # 迭代数量\\n                      verbose=0, # 无输出\\n                      batch_size=1000, # 每个批量的观测数\\n                      validation_data=(test_features, test_target)) # 用于评估的数据\\n```\\n\\n具体来说，我们展示神经网络在训练和测试集上的每个迭代的准确率得分。\\n\\n```py\\n# 获取训练和测试准确率历史\\ntraining_accuracy = history.history['acc']\\ntest_accuracy = history.history['val_acc']\\n\\n# 创建迭代数量\\nepoch_count = range(1, len(training_accuracy) + 1)\\n\\n# 可视化准确率历史\\nplt.plot(epoch_count, training_accuracy, 'r--')\\nplt.plot(epoch_count, test_accuracy, 'b-')\\nplt.legend(['Training Accuracy', 'Test Accuracy'])\\nplt.xlabel('Epoch')\\nplt.ylabel('Accuracy Score')\\nplt.show();\\n```\\n\\n![png](https://chrisalbon.com/deep_learning/keras/visualize_performance_history/visualize_performance_history_12_0.png)\\n\\n## 神经网络的 K 折交叉验证\\n\\n如果我们拥有较小的数据，那么利用 k 折叠交叉验证可以最大化我们评估神经网络表现的能力。 这在 Keras 中是可能的，因为我们可以“包装”任何神经网络，使其可以使用 scikit-learn 中可用的评估功能，包括 k-fold 交叉验证。 为此，我们首先要创建一个返回已编译神经网络的函数。 接下来我们使用`KerasClassifier`（这是分类器的情况，如果我们有一个回归器，我们可以使用`KerasRegressor`）来包装模型，以便 scikit-learn 可以使用它。 在此之后，我们可以像任何其他 scikit-learn 学习算法一样使用我们的神经网络（例如随机森林，逻辑回归）。 在我们的解决方案中，我们使用`cross_val_score`在我们的神经网络上运行三折交叉验证。\\n\\n```py\\n# 加载库\\nimport numpy as np\\nfrom keras import models\\nfrom keras import layers\\nfrom keras.wrappers.scikit_learn import KerasClassifier\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.datasets import make_classification\\n\\n# 设置随机数种子\\nnp.random.seed(0)\\n\\n# 使用 TensorFlow 后端\\n\\n# 特征数\\nnumber_of_features = 100\\n\\n# 生成特征矩阵和目标向量\\nfeatures, target = make_classification(n_samples = 10000,\\n                                       n_features = number_of_features,\\n                                       n_informative = 3,\\n                                       n_redundant = 0,\\n                                       n_classes = 2,\\n                                       weights = [.5, .5],\\n                                       random_state = 0)\\n\\n# 创建返回已编译网络的函数\\ndef create_network():\\n\\n    # 创建神经网络\\n    network = models.Sequential()\\n\\n    # 添加带有 ReLU 激活函数的全连接层\\n    network.add(layers.Dense(units=16, activation='relu', input_shape=(number_of_features,)))\\n\\n    # 添加带有 ReLU 激活函数的全连接层\\n    network.add(layers.Dense(units=16, activation='relu'))\\n\\n    # 添加带有 Sigmoid 激活函数的全连接层\\n    network.add(layers.Dense(units=1, activation='sigmoid'))\\n\\n    # 编译神经网络\\n    network.compile(loss='binary_crossentropy', # 交叉熵\\n                    optimizer='rmsprop', # RMSProp\\n                    metrics=['accuracy']) # 准确率表现度量\\n\\n    # 返回编译的网络\\n    return network\\n\\n# 包装 Keras 模型，使其能够用于 scikit-learn\\nneural_network = KerasClassifier(build_fn=create_network, \\n                                 epochs=10, \\n                                 batch_size=100, \\n                                 verbose=0)\\n\\n# 使用三折交叉验证评估神经网络\\ncross_val_score(neural_network, features, target, cv=3)\\n\\n# array([ 0.90491901,  0.77827782,  0.87038704]) \\n```\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern2 = r'Epoch\\s*(\\d+)/\\d+.*? - accuracy:\\s*(\\d+\\.\\d+)\\s*- loss:\\s*(\\d+\\.\\d+)(?:.*? - val_accuracy:\\s*(\\d+\\.\\d+)\\s*- val_loss:\\s*(\\d+\\.\\d+))?'\n",
    "matches = re.findall(pattern2, soup.text, re.DOTALL)\n",
    "soup.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
