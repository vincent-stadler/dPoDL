{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee47bc82-f297-4c8e-b5e1-d48e5959c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2d4ce3-d1e7-459e-b86c-999b47acfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82f6eb26-82df-434b-91a6-720e714d47be",
   "metadata": {},
   "source": [
    "# save all python notebooks on kaggle\n",
    "with open(\"output-2.txt\", \"w\") as file:\n",
    "    for i in range(21):  # Change range as needed\n",
    "        i += 1\n",
    "        result = subprocess.run(\n",
    "            f\"kaggle kernels list --page-size 50 -v --kernel-type notebook --language python --page {i}\",\n",
    "            shell=True,\n",
    "            stdout=file,\n",
    "            stderr=subprocess.STDOUT\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ff325fb-5359-4146-a54c-0a77aa6637cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST RUN\n",
    "def extract_metrics_kaggle(url):\n",
    "    #url = 'https://www.kaggle.com/code/m1nty03/rice-type-classification'\n",
    "    name = url.split(\"www.kaggle.com/code/\")\n",
    "    name = name[-1].replace(\"/\", \"--\")\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, 'rendered-kernel-content'))\n",
    "    )\n",
    "    \n",
    "    iframe = driver.find_element(By.ID, 'rendered-kernel-content')\n",
    "    iframe_src = iframe.get_attribute('src')\n",
    "    response = requests.get(iframe_src)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    return regex_metrics(soup)\n",
    "\n",
    "\n",
    "def regex_metrics(text, name):\n",
    "    # Define individual regex patterns for each metric\n",
    "    epoch_pattern = r'Epoch\\s*(\\d+)/\\d+'\n",
    "    loss_pattern = r' loss:\\s*(\\d+\\.\\d+)'\n",
    "    acc_pattern = r' acc(?:uracy)?:\\s*(\\d+\\.\\d+)'\n",
    "    val_loss_pattern = r' val_loss:\\s*(\\d+\\.\\d+)'\n",
    "    val_acc_pattern = r' val_acc(?:uracy)?:\\s*(\\d+\\.\\d+)'\n",
    "    \n",
    "    epoch_matches = re.findall(epoch_pattern, text)\n",
    "    loss_matches = re.findall(loss_pattern, text)\n",
    "    acc_matches = re.findall(acc_pattern, text)\n",
    "    val_loss_matches = re.findall(val_loss_pattern, text)\n",
    "    val_acc_matches = re.findall(val_acc_pattern, text)\n",
    "    \n",
    "    for metric in [loss_matches, acc_matches, val_loss_matches, val_acc_matches]:\n",
    "        if len(metric) != len(epoch_matches):\n",
    "            metric[:] = [None] * len(epoch_matches)\n",
    "        else:\n",
    "            metric[:] = [float(i) for i in metric]\n",
    "    epoch_matches = [int(i) for i in epoch_matches]\n",
    "    \n",
    "    # List to hold the structured data\n",
    "    structured_data = list(zip(epoch_matches, acc_matches, loss_matches, val_acc_matches, val_loss_matches))\n",
    "    \n",
    "    # Create a DataFrame for better readability\n",
    "    df = pd.DataFrame(structured_data, columns=['Epoch', 'Accuracy', 'Loss', 'Val_Accuracy', 'Val_Loss'])\n",
    "    if len(df) > 0:\n",
    "        print(f\"found {len(df)} metrics for {name}\")\n",
    "        df.to_csv(name + \".csv\", index=False)\n",
    "        return df\n",
    "    else:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec5678-7b56-4063-8a9d-e18444cfa6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = pd.read_csv(\"output.txt\")\n",
    "for ref in tqdm(list(refs[\"ref\"])[120:]):\n",
    "    url = \"https://www.kaggle.com/code/\" + ref\n",
    "    #print(f\"processing url {url}\")\n",
    "    try:\n",
    "        extract_metrics_kaggle(url)\n",
    "    except Exception as e:\n",
    "        print(url, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cfa948-47ed-44a4-9cdf-99d472a61386",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801f862-34d4-4941-8745-20dbfc200a3b",
   "metadata": {},
   "source": [
    "## GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f94d64b-b1d1-4cf3-8475-f9939206c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Replace with your GitHub personal access token\n",
    "GITHUB_TOKEN = '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'\n",
    "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
    "\n",
    "# GitHub Search API query for notebooks containing \"Epoch 1/\"\n",
    "search_query = 'Epoch 1/'\n",
    "search_url = f'https://api.github.com/search/code?q={search_query}'\n",
    "response = requests.get(search_url, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44cc6ff7-0c53-4b29-8ca3-d21fedbb463c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 2 metrics for TeamVanDeep--ICPR_MTWI_2018_section1\n",
      "found 60 metrics for rtu715--NAS-Bench-360\n",
      "found 106 metrics for zhangweichen2006--iCAN\n",
      "found 14 metrics for archcra--wu-hu-qi\n",
      "found 2 metrics for tbass134--DogBreedDectector\n",
      "found 175 metrics for KjellbergGustav--Deeplearning-project\n",
      "found 98 metrics for MoatazEldeeb--FER2013-CNN\n",
      "found 100 metrics for samils7--lung-segmentation-xray\n"
     ]
    }
   ],
   "source": [
    "# Fetch search results from GitHub API\n",
    "if response.status_code == 200:\n",
    "    results = response.json()\n",
    "    for item in results['items'][:10]:\n",
    "        # Construct the raw URL for the notebook\n",
    "        repo = item['repository']['full_name']\n",
    "        path = item['path']\n",
    "        raw_url = f'https://raw.githubusercontent.com/{repo}/master/{path}'\n",
    "        \n",
    "        r = requests.get(raw_url)\n",
    "        soup = bs(r.text, 'html.parser')\n",
    "\n",
    "        name = raw_url.split(\"https://raw.githubusercontent.com/\")[1]\n",
    "        name = name.split(\"/\")\n",
    "        name = \"--\".join(name[:2])\n",
    "        regex_metrics(soup.text, name)\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f26aa40-10c4-4a81-88f5-e788a726373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://raw.githubusercontent.com/samils7/lung-segmentation-xray/master/0.txt'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_url\n",
    "pyytorch!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
