{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee47bc82-f297-4c8e-b5e1-d48e5959c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82f6eb26-82df-434b-91a6-720e714d47be",
   "metadata": {},
   "source": [
    "# save all python notebooks on kaggle\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "with open(\"output-2.txt\", \"w\") as file:\n",
    "    for i in range(21):  # Change range as needed\n",
    "        i += 1\n",
    "        result = subprocess.run(\n",
    "            f\"kaggle kernels list --page-size 50 -v --kernel-type notebook --language python --page {i}\",\n",
    "            shell=True,\n",
    "            stdout=file,\n",
    "            stderr=subprocess.STDOUT\n",
    "        )\n",
    "\n",
    "# TEST RUN\n",
    "def extract_metrics_kaggle(url):\n",
    "    #url = 'https://www.kaggle.com/code/m1nty03/rice-type-classification'\n",
    "    name = url.split(\"www.kaggle.com/code/\")\n",
    "    name = name[-1].replace(\"/\", \"--\")\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, 'rendered-kernel-content'))\n",
    "    )\n",
    "    \n",
    "    iframe = driver.find_element(By.ID, 'rendered-kernel-content')\n",
    "    iframe_src = iframe.get_attribute('src')\n",
    "    response = requests.get(iframe_src)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    return regex_metrics(soup)\n",
    "\n",
    "refs = pd.read_csv(\"output.txt\")\n",
    "for ref in tqdm(list(refs[\"ref\"])[120:]):\n",
    "    url = \"https://www.kaggle.com/code/\" + ref\n",
    "    #print(f\"processing url {url}\")\n",
    "    try:\n",
    "        extract_metrics_kaggle(url)\n",
    "    except Exception as e:\n",
    "        print(url, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff325fb-5359-4146-a54c-0a77aa6637cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define individual regex patterns for each metric\n",
    "epoch_pattern_tf = r'epoch\\s*[\\[\\(]?\\s*(\\d+)\\s*/\\s*\\d+[\\]\\)]?'  \n",
    "loss_pattern_tf = r' loss:\\s*(\\d+\\.\\d+)'\n",
    "acc_pattern_tf = r' acc(?:uracy)?:\\s*(\\d+\\.\\d+)'\n",
    "val_loss_pattern_tf = r' val_loss:\\s*(\\d+\\.\\d+)'\n",
    "val_acc_pattern_tf = r' val_acc(?:uracy)?:\\s*(\\d+\\.\\d+)'\n",
    "\n",
    "iter_pattern_pytorch =  r'iter\\s*\\[(\\d+)\\s*/\\s*\\d+\\]'\n",
    "epoch_pattern_pytorch = r'epoch\\s*[\\[\\(]?\\s*(\\d+)\\s*/\\s*\\d+[\\]\\)]?' \n",
    "loss_pattern_pytorch = r' loss:\\s*(\\d+\\.\\d+)'\n",
    "acc_pattern_pytorch = r' top1:\\s*(\\d+\\.\\d+)'\n",
    "val_loss_pattern_pytorch = r' val_loss:\\s*(\\d+\\.\\d+)'\n",
    "val_acc_pattern_pytorch = r' val_top1:\\s*(\\d+\\.\\d+)'\n",
    "\n",
    "\n",
    "def regex_metrics_py(text, name):\n",
    "    text = text.lower()\n",
    "\n",
    "    iteration_matches= re.findall(iter_pattern_pytorch, text)\n",
    "    epoch_matches = re.findall(epoch_pattern_pytorch, text)\n",
    "    loss_matches = re.findall(loss_pattern_pytorch, text)\n",
    "    acc_matches = re.findall(acc_pattern_pytorch, text)\n",
    "    val_loss_matches = re.findall(val_loss_pattern_pytorch, text)\n",
    "    val_acc_matches = re.findall(val_acc_pattern_pytorch, text)\n",
    "\n",
    "    epoch_matches = [int(i) for i in epoch_matches]\n",
    "    epoch_matches = [i+1 for i in range(max(epoch_matches))]\n",
    "    \n",
    "    for metric in [val_loss_matches, val_acc_matches]:\n",
    "        if len(metric) != len(epoch_matches):\n",
    "            metric[:] = [None] * len(epoch_matches)\n",
    "        else:\n",
    "            metric[:] = [round(float(i)/100, 4) for i in metric]\n",
    "    \n",
    "    for metric in [loss_matches, acc_matches]:\n",
    "        if len(metric) != len(iteration_matches):\n",
    "            metric[:] = [None] * len(iteration_matches)\n",
    "        else:\n",
    "            metric[:] = [round(float(i)/100, 4) for i in metric]\n",
    "\n",
    "    last_loss = []\n",
    "    last_acc = []\n",
    "    step_size = len(loss_matches) // len(epoch_matches) if len(epoch_matches) > 0 else 1  # no division by 0\n",
    "    for ix in range(len(epoch_matches)):\n",
    "        try:\n",
    "            last_acc.append(acc_matches[ix * step_size])\n",
    "            last_loss.append(loss_matches[ix * step_size])\n",
    "        except IndexError:\n",
    "            last_loss.append(None)\n",
    "            last_acc.append(None)\n",
    "            \n",
    "    structured_data1 = list(zip(epoch_matches, val_acc_matches, val_loss_matches, last_acc, last_loss))\n",
    "    df1 = pd.DataFrame(structured_data1, columns=['Epoch', 'Val_Accuracy', 'Val_Loss', 'Accuracy', 'Loss'])\n",
    "    if len(df1) > 0:\n",
    "        print(f\"found {len(df1)} metrics for {name + 'epochs'}\")\n",
    "        df1.to_csv(name + \"-epochs.csv\", index=False)\n",
    "\n",
    "    \n",
    "    structured_data2 = list(zip(iteration_matches, acc_matches, loss_matches))\n",
    "    df2 = pd.DataFrame(structured_data2, columns=['Iteration', 'Accuracy', 'Loss'])\n",
    "    if len(df2) > 0:\n",
    "        print(f\"found {len(df2)} metrics for {name + 'iterations'}\")\n",
    "        df2.to_csv(name + \"-iterations.csv\", index=False)\n",
    "\n",
    "\n",
    "def regex_metrics_tf(text, name):\n",
    "    text = text.lower()\n",
    "\n",
    "    epoch_matches = re.findall(epoch_pattern_tf, text)\n",
    "    loss_matches = re.findall(loss_pattern_tf, text)\n",
    "    acc_matches = re.findall(acc_pattern_tf, text)\n",
    "    val_loss_matches = re.findall(val_loss_pattern_tf, text)\n",
    "    val_acc_matches = re.findall(val_acc_pattern_tf, text)\n",
    "    \n",
    "    for metric in [loss_matches, acc_matches, val_loss_matches, val_acc_matches]:\n",
    "        if len(metric) != len(epoch_matches):\n",
    "            metric[:] = [None] * len(epoch_matches)\n",
    "        else:\n",
    "            metric[:] = [float(i) for i in metric]\n",
    "    epoch_matches = [int(i) for i in epoch_matches]\n",
    "    \n",
    "    # List to hold the structured data\n",
    "    structured_data = list(zip(epoch_matches, acc_matches, loss_matches, val_acc_matches, val_loss_matches))\n",
    "    \n",
    "    # Create a DataFrame for better readability\n",
    "    df = pd.DataFrame(structured_data, columns=['Epoch', 'Accuracy', 'Loss', 'Val_Accuracy', 'Val_Loss'])\n",
    "    if len(df) > 0:\n",
    "        print(f\"found {len(df)} metrics for {name}\")\n",
    "        df.to_csv(name + \".csv\", index=False)\n",
    "        return df\n",
    "    else:\n",
    "        return\n",
    "\n",
    "#regex_metrics_py(text, \"test-test\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801f862-34d4-4941-8745-20dbfc200a3b",
   "metadata": {},
   "source": [
    "## GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723820c3-c676-4a5d-b610-5bdb229c0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub API search URL with pagination parameters\n",
    "GITHUB_TOKEN = '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'\n",
    "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0ba31-17c4-4887-b4f2-2b4203db0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_paginated_results(q, headers, per_page=100):\n",
    "    page = 0\n",
    "    all_items = []\n",
    "    \n",
    "    while True:\n",
    "        page += 1\n",
    "        search_url = f'https://api.github.com/search/code?q={q}&page={page}&per_page={per_page}'\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:  # reach API limit\n",
    "            r = requests.get(\"https://api.github.com/rate_limit\", headers=headers)\n",
    "            waiting_time = r.json()[\"resources\"][\"code_search\"][\"reset\"] - time.time()\n",
    "            print(\"waiting time:\", waiting_time, \"seconds\")\n",
    "            time.sleep(waiting_time)\n",
    "            raise ValueError(response.text)\n",
    "            \n",
    "        data = response.json()\n",
    "        # Check if items were returned\n",
    "        if 'items' in data and len(data['items']) > 0:\n",
    "            all_items.extend(data['items'])  # Add new items to the list\n",
    "        else:\n",
    "            break  # No more results or an error\n",
    "\n",
    "    return  [i[\"html_url\"].replace(\"https://github.com/\", \"https://raw.githubusercontent.com/\").replace(\"/blob\", \"\") for i in all_items]\n",
    "\n",
    "\n",
    "def scrape_github(q):\n",
    "    # Fetch results for the current date range\n",
    "    try:\n",
    "        urls = fetch_paginated_results(q, HEADERS)\n",
    "    except ValueError:\n",
    "        return scrape_github(q)\n",
    "    except Exception as e:  # to account for maybe timeout\n",
    "        print(e)\n",
    "        return\n",
    "    return urls\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the list to store all results across date ranges\n",
    "all_results = []\n",
    "queries_py = ['\"Epoch [1/\" AND \"pytorch\" AND \"loss: ' + str(1 + round(0.0001 * i, 4)) + '\"' for i in range(1, 10000)]\n",
    "queries_tf = ['\"Epoch 1/\" AND \"tensorflow\" AND \"loss: ' + str(round(0.0001 * i, 4)) + '\"' for i in range(1, 10000)]\n",
    "\n",
    "for query in tqdm(queries_tf):\n",
    "    urls = scrape_github(query)\n",
    "    all_results.extend(urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5542d08-63b8-408f-972a-ad09587e4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://api.github.com/rate_limit\", headers=H)\n",
    "t = r.json()[\"resources\"][\"code_search\"][\"reset\"]\n",
    "print(\"reset:\", t, \"\\nnow:  \", time.time())\n",
    "print(\"difference\", t-time.time())\n",
    "print(r.json()[\"resources\"][\"code_search\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc6ff7-0c53-4b29-8ca3-d21fedbb463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch search results from GitHub API\n",
    "\n",
    "results = response.json()\n",
    "for raw_url in all_results[:10]:\n",
    "    # Construct the raw URL for the notebook\n",
    "    #repo = item['repository']['full_name']\n",
    "    #path = item['path']\n",
    "    #raw_url = f'https://raw.githubusercontent.com/{repo}/master/{path}'\n",
    "    \n",
    "    r = requests.get(raw_url)\n",
    "    soup = bs(r.text, 'html.parser')\n",
    "\n",
    "    name = raw_url.split(\"https://raw.githubusercontent.com/\")[1]\n",
    "    name = name.split(\"/\")\n",
    "    name = \"--\".join(name[:2])\n",
    "    regex_metrics(soup.text, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c465c-7c36-4e7c-9eac-59b5b2aae5f2",
   "metadata": {},
   "source": [
    "# Selenium GitHub Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223d3640-2045-46d4-8d6a-e00cc35277ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "un = \"vincent-stadler\"\n",
    "pw = \"\"\n",
    "query_urls = ['https://github.com/search?q=%22Epoch+1%2F%22+AND+%22tensorflow%22+AND+%22loss%3A+{}%22&type=code&p={}'.format(str(round(0.0001 * i, 4)), str(j+1)) for i in range(1, 10000) for j in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e34b0bf-97af-4bef-a164-0f62a1e2c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(d):\n",
    "    d.get(\"https://github.com/login\")\n",
    "\n",
    "    wait = WebDriverWait(d, 10)\n",
    "    username_field = wait.until(EC.presence_of_element_located((By.ID, \"login_field\")))\n",
    "    username_field.send_keys(un)\n",
    "    \n",
    "    # Input the password\n",
    "    password_field = d.find_element(By.ID, \"password\")\n",
    "    password_field.send_keys(pw)\n",
    "    \n",
    "    password_field.send_keys(Keys.RETURN)\n",
    "    wait.until(EC.url_changes(\"https://github.com/login\"))\n",
    "\n",
    "def find_links(soup):\n",
    "    l = []\n",
    "    items = soup.find_all(\"div\", \"bmcJak\")\n",
    "    if len(items) > 0:\n",
    "        for item in items:\n",
    "            try:\n",
    "                link = item.find(\"a\", \"gwACeB\")[\"href\"]\n",
    "                link = (\"https://raw.githubusercontent.com\" + link).replace(\"/blob\", \"\")\n",
    "                l.append(link)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return l\n",
    "\n",
    "def fetch_links(d, url):\n",
    "    d.get(url)\n",
    "    WebDriverWait(d, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, 'Box-sc-g0xbh4-0'))\n",
    "    )\n",
    "    soup = bs(d.page_source, 'html.parser')\n",
    "    return find_links(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94581ada-4142-4ab9-9467-751b2dc2bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_drivers = []\n",
    "for i in range(10):\n",
    "    _ = webdriver.Chrome()\n",
    "    login(_)\n",
    "    active_drivers.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f043a34-394f-439d-8de5-bb4ee9fe974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=len(active_drivers)) as executor:\n",
    "    futures = []\n",
    "    for i, url in enumerate(tqdm(query_urls[213 + 333 + 639:])):\n",
    "        driver = active_drivers[i % len(active_drivers)]  # Round-robin assignment of drivers\n",
    "        futures.append(executor.submit(fetch_links, driver, url))\n",
    "    \n",
    "    # Collecting results as they complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        links.extend(future.result())  # Add the parsed soup to soups list\n",
    "        print(\"Len links:\", len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdcc4ca0-13b4-408a-882a-335d779a4894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                          | 639/49449 [34:35<44:01:44,  3.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m tqdm(query_urls[\u001b[38;5;241m213\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m333\u001b[39m:]):  \u001b[38;5;66;03m#213 + 333\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m      3\u001b[0m     WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m      4\u001b[0m         EC\u001b[38;5;241m.\u001b[39mpresence_of_element_located((By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox-sc-g0xbh4-0\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      5\u001b[0m     soup \u001b[38;5;241m=\u001b[39m bs(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:363\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\urllib3\\request.py:81\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     78\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     82\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     83\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\urllib3\\request.py:173\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    170\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    171\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    716\u001b[0m     conn,\n\u001b[0;32m    717\u001b[0m     method,\n\u001b[0;32m    718\u001b[0m     url,\n\u001b[0;32m    719\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    720\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    721\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    722\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    723\u001b[0m )\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for url in tqdm(query_urls[213 + 333 + 639:]):  #213 + 333 + 639\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, 'Box-sc-g0xbh4-0')))\n",
    "    soup = bs(driver.page_source, 'html.parser')\n",
    "    links.extend(find_links(soup))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76b91a45-dd5a-4cb8-9798-57f61da9e08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13040"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fe83838-fd6b-41cb-b41d-13e9470bf5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_urls.index(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "565a06aa-532c-487f-8fe1-3625ed6f2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"links1.pickle\", \"wb\") as f:\n",
    "    pickle.dump(links, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
